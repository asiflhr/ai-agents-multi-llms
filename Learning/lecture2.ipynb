{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallelization: Distributes independent subtasks across multiple LLMs for concurrent processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # Load environment variables from .env file\n",
    "\n",
    "# Corrected way to retrieve the API key\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "if not api_key:\n",
    "    raise ValueError(\"GOOGLE_API_KEY not found. Make sure it's set in the .env file.\")\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = api_key\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash-latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What is the meaning of life?\n",
      "A: There's no single, universally accepted answer to the question of the meaning of life.  It's a deeply personal and philosophical question that has been pondered by humans for millennia.  Different individuals and cultures find meaning in various things, including:\n",
      "\n",
      "* **Relationships:**  Love, family, friendship, and community provide a sense of belonging and purpose for many.\n",
      "* **Contribution:**  Making a difference in the world, whether through work, volunteering, or creative expression, can give life meaning.\n",
      "* **Growth and learning:**  Continuously expanding one's knowledge, skills, and understanding can be a fulfilling pursuit.\n",
      "* **Spiritual or religious beliefs:**  Faith and connection to something greater than oneself provide meaning and guidance for many.\n",
      "* **Experiences:**  Travel, adventure, and pursuing passions can create rich and meaningful memories.\n",
      "* **Creativity and self-expression:**  Expressing oneself through art, music, writing, or other creative outlets can be deeply fulfilling.\n",
      "* **Personal fulfillment:**  Achieving personal goals, developing one's potential, and living in accordance with one's values.\n",
      "\n",
      "Ultimately, the meaning of life is what you make it.  It's a question to be explored and answered personally throughout your life, and the answer may evolve and change over time.  There's no right or wrong answer; the important thing is to find what resonates with you and gives your life purpose and significance.\n",
      "\n",
      "Q: What is the capital of France?\n",
      "A: Paris\n",
      "\n",
      "Q: What is the capital of Germany?\n",
      "A: Berlin\n",
      "\n",
      "Q: What is the capital of Italy?\n",
      "A: Rome\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This abstract representation a pool of threads which can be use to to execute callables/tasks in parallel.\n",
    "from concurrent.futures import ThreadPoolExecutor # For parallel processing\n",
    "\n",
    "# List of questions to ask the model\n",
    "questions = [\n",
    "    \"What is the meaning of life?\",\n",
    "    \"What is the capital of France?\",\n",
    "    \"What is the capital of Germany?\",\n",
    "    \"What is the capital of Italy?\",\n",
    "]\n",
    "\n",
    "# Function to process a single thread\n",
    "def process_question(question):\n",
    "    \"\"\"This function processes a single question and returns the answer.\"\"\"\n",
    "    return llm.invoke(f\"Q: {question}\")\n",
    "\n",
    "# Create a thread pool with 5 threads\n",
    "with ThreadPoolExecutor(max_workers=3) as executor:\n",
    "    # Process all questions in parallel\n",
    "    answers = list(executor.map(process_question, questions))\n",
    "\n",
    "# Print the answers\n",
    "for question, answer in zip(questions, answers):\n",
    "    print(f\"Q: {question}\\nA: {answer.content}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework: Try to add context to the message and see if the results are better or not for questions\n",
    "\n",
    "Note: This is just a demo to show how parallelization works. Python has some considerations for parallelization. (will be covered in future lectures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Routing: Dynamically select specialized LLM paths based on input characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\" 'Life Insurance'\", \" 'Health Insurance'\", \" 'Car Insurance'\", \" 'Home Insurance'\", \" 'General Consultation' \"]\n"
     ]
    }
   ],
   "source": [
    "options =\"\"\" 'Life Insurance', 'Health Insurance', 'Car Insurance', 'Home Insurance', 'General Consultation' \"\"\"\n",
    "print(options.split(\",\"))\n",
    "input_text = \"I want to know more about Life Insurance\"\n",
    "\n",
    "selection_prompt = f\"\"\"\n",
    "user query: {input_text}\n",
    "Analyze the user query and select the appropriate option from the following list: {options.split(\",\")}.\n",
    "Fist explain your reasoning and then give me the answer in this XML format:\n",
    "\n",
    "<reasoning>\n",
    "Explain your reasoning here.\n",
    "</reasoning>\n",
    "<answer>\n",
    "The answer goes here.\n",
    "</answer>\n",
    "\"\"\"\n",
    "\n",
    "result = llm.invoke(selection_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Option: 'Life Insurance'\n",
      "Reasoning: The user explicitly states \"I want to know more about Life Insurance\".  This directly indicates their interest in life insurance and not any other type of insurance or general consultation.  The query contains the keywords \"Life Insurance\", making it unambiguous.\n"
     ]
    }
   ],
   "source": [
    "def extract_option(result):\n",
    "    return result.content.split(\"<answer>\")[1].split(\"</answer>\")[0].strip()\n",
    "\n",
    "def extract_reasoning(result):\n",
    "    return result.content.split(\"<reasoning>\")[1].split(\"</reasoning>\")[0].strip()\n",
    "\n",
    "option = extract_option(result)\n",
    "reasoning = extract_reasoning(result)\n",
    "\n",
    "print(f\"Option: {option}\")\n",
    "print(f\"Reasoning: {reasoning}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "\"'Life Insurance'\"\n"
     ]
    }
   ],
   "source": [
    "option\n",
    "print(type(option))\n",
    "print(repr(option))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Life Insurance Toll free number: 1800-123-4567\n"
     ]
    }
   ],
   "source": [
    "# Based on the reasoning, print the tool free number( or any other information) for the selected option which is powered by business logic\n",
    "# Remove extra single quotes if present\n",
    "option = option.strip(\"'\")\n",
    "\n",
    "if option=='Life Insurance':\n",
    "    print(\"Life Insurance Toll free number: 1800-123-4567\")\n",
    "elif option == \"Health Insurance\":\n",
    "    print(\"Health Insurance Toll free number: 1800-234-5678\")\n",
    "elif option == \"Car Insurance\":\n",
    "    print(\"Car Insurance Toll free number: 1800-345-6789\")\n",
    "elif option == \"Home Insurance\":\n",
    "    print(\"Home Insurance Toll free number: 1800-456-7890\")\n",
    "else:\n",
    "    print(\"General Consultation Toll free number: 1800-567-8901\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
